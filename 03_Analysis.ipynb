{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gdal, osr\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "#import fiona"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib.colors import ListedColormap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RasterProp:\n",
    "    def __init__(self,\n",
    "                 rasterFile,\n",
    "                 sliceClass=None, slicing = False):\n",
    "        self.raster = gdal.Open(rasterFile)\n",
    "        self.geotransform = self.raster.GetGeoTransform()\n",
    "        self.projRef      = self.raster.GetProjectionRef()\n",
    "        self.originX = self.geotransform[0]\n",
    "        self.originY = self.geotransform[3] \n",
    "        self.pixelWidth = self.geotransform[1] \n",
    "        self.pixelHeight = self.geotransform[5]\n",
    "        \n",
    "        if slicing:\n",
    "            print('recomputing origin')\n",
    "            x_ori_rel , y_ori_rel, xlen, ylen = sliceClass.relevantArea()\n",
    "            self.originX, self.originY = pixel2coord(self.geotransform, \n",
    "                                                     x_ori_rel, \n",
    "                                                     y_ori_rel)\n",
    "            \n",
    "def array2raster(array, rasProp,newRasterfn):\n",
    "    print('converting array to raster...')\n",
    "    cols = array.shape[1]\n",
    "    rows = array.shape[0]\n",
    "    driver = gdal.GetDriverByName('GTiff')\n",
    "    outRaster = driver.Create( newRasterfn, \n",
    "                              cols, rows,\n",
    "                              bands=1, \n",
    "                              eType= gdal.GDT_Float32)\n",
    "    outRaster.SetGeoTransform((rasProp.originX, \n",
    "                               rasProp.pixelWidth, \n",
    "                               0, rasProp.originY, \n",
    "                               0, rasProp.pixelHeight))\n",
    "    \n",
    "    outband = outRaster.GetRasterBand(1)\n",
    "    outband.WriteArray(array)\n",
    "    outRasterSRS = osr.SpatialReference()\n",
    "    outRasterSRS.ImportFromWkt(rasProp.projRef)\n",
    "    outRaster.SetProjection(outRasterSRS.ExportToWkt())\n",
    "    outband.FlushCache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def raster2array(rasterfn):\n",
    "    #print('converting raster to array...')\n",
    "    raster = gdal.Open(rasterfn)\n",
    "    band = raster.GetRasterBand(1)\n",
    "    array = band.ReadAsArray()\n",
    "    return array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "sloCost = raster2array(os.path.abspath('01_Data500/slope.tif'))\n",
    "envCost = raster2array(os.path.abspath('01_Data500/fac_env.tif'))\n",
    "infCost = raster2array(os.path.abspath('01_Data500/fac_inf.tif'))\n",
    "pubCost = raster2array(os.path.abspath('01_Data500/fac_pub.tif'))\n",
    "allCost = (ecoCost+envCost+infCost+pubCost)/4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Line Length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "epi111P = os.path.abspath('02_DC_Projects_DE/02_dc5_paths/eip_111'+'.npy')\n",
    "eip111 = np.load(epi111P)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Line length as number of cells"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lineLength_numberOfCells(lineIdx):\n",
    "    return len(lineIdx[0])     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lineLength(lineArray):\n",
    "    indicies = np.nonzero(lineArray)\n",
    "    indicies_paired = np.stack((indicies[0],indicies[1]), axis=-1)\n",
    "    disTot = 0\n",
    "    for point in range(1,len(indicies_paired)-1,1):\n",
    "        x1 = indicies_paired[point-1][0]\n",
    "        y1 = indicies_paired[point-1][1]\n",
    "        x2 = indicies_paired[point][0]\n",
    "        y2 = indicies_paired[point][1]\n",
    "        dist = np.sqrt((x2-x1)**2+(y2-y1)**2)*0.5\n",
    "        disTot = disTot+dist\n",
    "    return disTot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Line length based on number of cells multiplied by 0.5 (raster size=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lineLength_idx(lineIdx):\n",
    "    indicies_paired = np.transpose(lineIdx)\n",
    "    disTot = 0\n",
    "    for point in range(1,len(indicies_paired)-1,1):\n",
    "        x1 = indicies_paired[point-1][0]\n",
    "        y1 = indicies_paired[point-1][1]\n",
    "        x2 = indicies_paired[point][0]\n",
    "        y2 = indicies_paired[point][1]\n",
    "        dist = np.sqrt((x2-x1)**2+(y2-y1)**2)*0.5\n",
    "        disTot = disTot+dist\n",
    "    return int(disTot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.0615528128088303\n",
      "4493 4034 4494 4030\n",
      "1.5811388300841898\n",
      "4494 4030 4495 4027\n",
      "1.5811388300841898\n",
      "4495 4029 4496 4026\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "470"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lineLength_idx(np.load(os.path.abspath('02_DC_Projects_DE/02_dc5_paths/eip_'+'222'+'.npy')))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "toc-hr-collapsed": false
   },
   "source": [
    "# Population Affected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "popu = raster2array(os.path.abspath('01_Data500/population.tif'))\n",
    "def peopleAff(line):\n",
    "    return popu[line[0],line[1]].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def peopleAffected(line, basedOn):\n",
    "    path = line_path(path_based_on=basedOn, dc = line)\n",
    "    return np.multiply(popu,path).sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Corine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "corOrig = os.path.abspath('01_Data500/corine_500_original_classification.tif')\n",
    "landOrig = raster2array(corOrig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "corClas = pd.read_csv('Corine_Classification.csv', delimiter=';')[['CLC','Class_name']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def corineClassPath(factor, line):\n",
    "    dc1EcoPath = line_path(path_based_on=factor,dc=line)\n",
    "    dc1EcoCor = np.multiply(dc1EcoPath,landOrig)\n",
    "    value, counts = np.unique(dc1EcoCor, return_counts=True)\n",
    "    corPath = pd.DataFrame([value,counts]).T\n",
    "    corPath.columns =['CLC','count']\n",
    "    corClasPath = corPath.set_index('CLC').join(corClas.set_index('CLC'))\n",
    "    corClasDef = corClasPath.dropna().groupby('Class_name').sum()\n",
    "    corClasDef.columns = [factor]\n",
    "    return corClasDef"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getCorineClass(line):\n",
    "    dc1Eco = corineClassPath(factor='eco',line=line)\n",
    "    dc1Env = corineClassPath(factor='env',line=line)\n",
    "    dc1Inf = corineClassPath(factor='inf',line=line)\n",
    "    dc1Pub = corineClassPath(factor='pub',line=line)\n",
    "    dc1All = corineClassPath(factor='all',line=line)\n",
    "    dc1CorFac = dc1Eco.join(dc1Env, \n",
    "                            how='outer').join(dc1Inf,\n",
    "                                             how='outer').join(dc1Pub, how='outer').join(dc1All, how='outer')\n",
    "    return dc1CorFac"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Corine Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "corOrig = raster2array(os.path.abspath('01_Data500/corine_500_original_classification.tif'))\n",
    "def getCorineCLC(line):\n",
    "    clcCode, clcCounts = np.unique(corOrig[line[0],line[1]], return_counts=True)\n",
    "    return dict(zip(clcCode, clcCounts))\n",
    " \n",
    "corClass = pd.read_excel('Corine_Classification.xlsx').set_index('CLC')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 'Similarness' of the path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "toc-hr-collapsed": false
   },
   "source": [
    "## Buffer Intersection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Approch**\n",
    "\n",
    "Create a buffer of 1.5KM (randomly choosen number) and calculating the fraction of intersection of the two buffer zones.\n",
    "\n",
    "**Method**\n",
    "\n",
    "*Step1:* Select cell indexes with path (non-zero values with path array). A list of tuples is created containing the path\n",
    "\n",
    "*Step2:* Add the buffer tuples to the list of tuples. Here it is possible to change the buffer zone. This will add multiple tuples with same values. Hence, important to select only unique tuples. This is done with the set operator. \n",
    "\n",
    "*Step3:* Count the number of tuples common in the paths been compared\n",
    "\n",
    "*Step4:* Normalize with the number of cells in the buffer zone of the normalized path. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getBuffPathLocations(line, bufferLength=3):\n",
    "    y,x = line[0], line[1]\n",
    "    orgList = list(zip(x,y))\n",
    "    bufList = []\n",
    "    for item in orgList:\n",
    "        for shift in range(0,bufferLength,1):\n",
    "            bufList.append((item[0]-shift, item[1]))\n",
    "            bufList.append((item[0]+shift, item[1]))\n",
    "            bufList.append((item[0]      , item[1]-shift))\n",
    "            bufList.append((item[0]      , item[1]+shift))\n",
    "\n",
    "            bufList.append((item[0]-shift, item[1]-shift))\n",
    "            bufList.append((item[0]+shift, item[1]+shift))\n",
    "\n",
    "            bufList.append((item[0]-shift, item[1]+shift))\n",
    "            bufList.append((item[0]+shift, item[1]-shift)) \n",
    "    return set(bufList)\n",
    "\n",
    "\n",
    "def getIntersection(bufRef, bufList2):\n",
    "    intLen = len(bufRef.intersection(bufList2))\n",
    "    return intLen/len(bufRef)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1211, 1212, 1213, ..., 2103, 2104, 2105],\n",
       "       [4834, 4834, 4835, ..., 5445, 5446, 5447]], dtype=int64)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "line_eip111 = np.load(os.path.abspath('03_DC_Project_North/02_paths_2/eip_111.npy'))\n",
    "line_eip111"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "dc5Actual = raster2array(os.path.abspath('02_DC_Projects_DE/DC_5_real.tif'))\n",
    "dc5ActualIdx = np.nonzero(dc5Actual)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ProtectedZone length"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "protected zone as the sum of protected zone cell the line passes through."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "prot = raster2array(os.path.abspath('01_Data500/protected.tif'))\n",
    "def getProtectedCells(line):\n",
    "    return prot[line[0],line[1]].sum()/10\n",
    "#getProtectedCells(l1113)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Slope Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "sloCost = raster2array(os.path.abspath('01_Data500/slope.tif'))\n",
    "def returnSlopeClass(line):\n",
    "    slopVals = sloCost[line[0],line[1]]\n",
    "    slopValsCount = np.unique(np.digitize(slopVals, [1.146,4.574]), return_counts=True)[1]\n",
    "    return list(slopValsCount)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AllPaths"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculation of all the evaluation criterion for all the paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "peopleAffected = []\n",
    "protZonePassed = []\n",
    "lineLength     = []\n",
    "#buffInter_dc5Actual = []\n",
    "buffInter_eip111 =  []\n",
    "slopeClassData = []\n",
    "corineCLCCount = []\n",
    "lineNumberOfCells = []\n",
    "\n",
    "#refBuffAct = getBuffPathLocations(dc5ActualIdx)\n",
    "refBuff111 = getBuffPathLocations(line_eip111)\n",
    "for env in range(0,11,1):\n",
    "    for inf in range(0,11,1):\n",
    "        for pub in range(0,11,1):\n",
    "            if (env == inf==pub==0):\n",
    "                continue;\n",
    "                        \n",
    "            fileName = str(env)+str(inf)+str(pub)\n",
    "            comName = os.path.abspath('03_DC_Project_North/02_paths_2/eip_'+fileName+'.npy')\n",
    "            path = np.load(comName)\n",
    "            print(env,inf,pub)\n",
    "\n",
    "        # line number of cells\n",
    "            def lineNumCell():\n",
    "                linNumCell = lineLength_numberOfCells(path)\n",
    "                lineNumberOfCells.append([env/(env+inf+pub),\n",
    "                                            inf/(env+inf+pub),\n",
    "                                            pub/(env+inf+pub),linNumCell])\n",
    "\n",
    "\n",
    "        # line length\n",
    "            def lineLength():\n",
    "                print('linelength')\n",
    "                lineLen = lineLength_idx(path)\n",
    "                lineLength.append([env/(env+inf+pub),\n",
    "                                            inf/(env+inf+pub),\n",
    "                                            pub/(env+inf+pub),lineLen])\n",
    "\n",
    "\n",
    "        # corine CLC code\n",
    "\n",
    "            def corCLC():\n",
    "                print('corCLC')\n",
    "                corCLC = getCorineCLC(path)\n",
    "                corineCLCCount.append([env/(env+inf+pub),\n",
    "                                       inf/(env+inf+pub),\n",
    "                                       pub/(env+inf+pub),corCLC])\n",
    "\n",
    "\n",
    "        # slope class\n",
    "            def slopClass():\n",
    "\n",
    "                print('slope class')\n",
    "                slopClass = [env/(env+inf+pub), \n",
    "                                         inf/(env+inf+pub), \n",
    "                                         pub/(env+inf+pub), \n",
    "                                         returnSlopeClass(path)[0],\n",
    "                                         returnSlopeClass(path)[1],\n",
    "                                         returnSlopeClass(path)[2]]\n",
    "                slopeClassData.append(slopClass)\n",
    "\n",
    "\n",
    "        # people affected\n",
    "            def peopleAffVal():\n",
    "\n",
    "                print('People Aff')\n",
    "                linPplAff = peopleAff(path)\n",
    "                peopleAffected.append([env/(env+inf+pub),\n",
    "                                               inf/(env+inf+pub),\n",
    "                                               pub/(env+inf+pub),linPplAff])\n",
    "\n",
    "\n",
    "        # buffer wrt to actual\n",
    "        #            print('actBuff')\n",
    "        #            buffInt = getIntersection(refBuffAct,\n",
    "        #                                      getBuffPathLocations(path))\n",
    "        #            buffInter_dc5Actual.append([env/(env+inf+pub),\n",
    "         #                                  inf/(env+inf+pub),\n",
    "         #                                  pub/(env+inf+pub),buffInt])\n",
    "\n",
    "        # buffer wrt to eip_111\n",
    "            print('111Buff')\n",
    "            buffInt = getIntersection(refBuff111,\n",
    "                                        getBuffPathLocations(path))\n",
    "            buffInter_eip111.append([env/(env+inf+pub),\n",
    "                                        inf/(env+inf+pub),\n",
    "                                        pub/(env+inf+pub),buffInt])\n",
    "\n",
    "\n",
    "        # protected zone cells\n",
    "            def protCells():\n",
    "\n",
    "                print('protCells')\n",
    "                protZnLin = getProtectedCells(path)\n",
    "                protZonePassed.append([env/(env+inf+pub),\n",
    "                                            inf/(env+inf+pub),\n",
    "                                            pub/(env+inf+pub),protZnLin])\n",
    "            lineNumCell()\n",
    "            #lineLength()\n",
    "            corCLC()\n",
    "            slopClass()\n",
    "            peopleAffVal()\n",
    "            protCells()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Restructuring and saving indicators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# similarness relative to actual (only valid for dc5)\n",
    "buff_actual = pd.DataFrame(buffInter_dc5Actual, \n",
    "                 columns=['env','inf','pub','buff_actual'])\n",
    "buff_actual.to_excel(os.path.abspath('03_DC_Project_North/03_analysis_2/eip_buff_actual.xlsx'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# similarness relative to 111 path\n",
    "buffeip111_paths = pd.DataFrame(buffInter_eip111, \n",
    "                columns=['env','inf','pub','buf_111'])\n",
    "buffeip111_paths.drop_duplicates().to_excel(os.path.abspath('03_DC_Project_North/03_analysis_2/eip_buff.xlsx'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# number of cells\n",
    "lineNumberOfCells_paths = pd.DataFrame(lineNumberOfCells,\n",
    "             columns=['env','inf','pub','line_numberOfCells'])\n",
    "lineNumberOfCells_paths.drop_duplicates().to_excel(os.path.abspath('03_DC_Project_North/03_analysis_2/eip_lineNumberOfCells.xlsx'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# people affected\n",
    "pplAffected_paths = pd.DataFrame(peopleAffected, \n",
    "                         columns=['env','inf','pub','peopleAff'])\n",
    "pplAffected_paths.drop_duplicates().to_excel(os.path.abspath('03_DC_Project_North/03_analysis_2/eip_peopleAffected.xlsx'))\n",
    "\n",
    "\n",
    "\n",
    "#dc5Lengths = pd.DataFrame(lineLength, \n",
    "#                         columns=['env','inf','pub','dc5Length'])\n",
    "#dc5Lengths.drop_duplicates().to_excel(os.path.abspath('03_DC_Project_North/03_analysis/eip_length.xlsx'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# protected zone cells\n",
    "dc5Protzon_paths = pd.DataFrame(protZonePassed, \n",
    "                         columns=['env','inf','pub','protZoneCells'])\n",
    "dc5Protzon_paths.drop_duplicates().to_excel(os.path.abspath('03_DC_Project_North/03_analysis_2/eip_protZoneCells.xlsx'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# slope classification\n",
    "slopClass_paths = pd.DataFrame(slopeClassData, columns={'env','inf','pub','low','med','high'})\n",
    "slopClass_paths.drop_duplicates().to_excel(os.path.abspath('03_DC_Project_North/03_analysis_2/eip_slopeClass.xlsx'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# \n",
    "CLCCount_paths = pd.DataFrame(corineCLCCount,\n",
    "                          columns={'env','inf','pub','clc_count'} )\n",
    "CLCCount_paths.to_excel(os.path.abspath('03_DC_Project_North/03_analysis_2/eip_clcCount.xlsx'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## corine mapping to defined classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corinClassification = []\n",
    "for row in dc5CLCCount.iterrows():\n",
    "    lineCounts = pd.DataFrame.from_dict(dict(row[1].clc_count), orient='index', columns=['clc_count'])\n",
    "    corineClassNameCount = corClass.join(lineCounts).fillna(0)[['Class_name','clc_count']].groupby('Class_name').sum().T\n",
    "    clasList = list(corineClassNameCount.values[0])\n",
    "    clasList.extend([row[1].env, row[1].inf, row[1].pub])\n",
    "   \n",
    "    corinClassification.append(clasList)\n",
    "   \n",
    "columns = ['Agriculture', 'Forest', 'HVN', 'Man-Made', 'Wasteland','env', 'inf', 'pub']\n",
    " \n",
    "corinClassDF = pd.DataFrame(corinClassification, columns=columns)\n",
    "corinClassDF.drop_duplicates().to_excel(os.path.abspath('03_DC_Project_North/03_analysis_2/eip_corinClassification.xlsx'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
